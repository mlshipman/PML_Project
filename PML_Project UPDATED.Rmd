## Practical Machine Learning Course Project
============================================================
### Michael Shipman - July 27, 2014

## Data Sourcing and Processing
The training and testing datasets were loaded directly from the cloudfront.net URL given in the assignement instructions.
```{r}
sourcetrain <- read.csv("pml-training.csv", header = TRUE)
sourcetest <- read.csv("pml-testing.csv", header = TRUE)
```
The structure of the source (raw) datasets were observed to have many statistical summary variables that would not contribute well to the prediction algorithms, such as min, max, average, kertosis, skewness, etc. The source training and testing data sets were conditioned by removing the statistical summary variables and checked to remove any rows with "NA" data entries. Further conditioning is performed to remove the "raw timestamps" part 1, part 3, and the observation number "X" column. This will produce 'tidy' datasets to work with while fitting and testing the data.
```{r}
#Create a matching vector of character strings that pertain to summary statistics phases.
match <- c("kurtosis", "skewness", "max", "min", "amplitude", "var", "avg", "stddev")
#Create a vector of variables to remove that contain summary statistics. 
removeVar <- names(sourcetrain)[grep(paste(match, collapse="|"), names(sourcetrain))]
#add the "X" column to the columns needed to remove
removeVar <- c(removeVar, "X")
#Remove the statistical summary variables from the source training and testing datasets.
train <- sourcetrain[ ,!(names(sourcetrain) %in% removeVar)]
test <- sourcetest[ ,!(names(sourcetest) %in% removeVar)]
#Ensure that all the data rows are complete (w/o "NA")
train <- train[complete.cases(train), ]
test <- test[complete.cases(test), ]
```
The training dataset was split into 75% / 25% training and validation dataset to fine tune the model.
```{r}
set.seed(28462)
split <- sample(1:dim(train)[1], 
                size=dim(train)*0.75,
                replace=F)
train <- train[split,]
val <- train[-split,]
```

##Selection and Training the Machine Learning Algorith Using Training Data
When the data sets were conditioned into 'tidy' format, the next step was to select a model to fit to the training data set. The output variable is a categorical variable listed from A to E corresponding to the excersize type being performed while the input variables were being measured. A Characterization and Regression Tree (CART) model was chosen based on the muliple discrete outcomes of the output variable. The CART model will produce a decision tree based on the input variables run through the algorithm. The 'rpart' algorithm in the Caret package was used as the first model to fit. A random number generator seed of 28462 was chosen and reset each time a new training algorithm was begun.
```{r}
library(caret)
library(rpart)
set.seed(28462)
#Calls the rpart model and fits to the conditioned training dataset.
fit <- rpart(classe ~ .,
               method = "class",
               data = train)
```
The descision tree final model is shown in the output and graphics below.
```{r}
#displays model fitting
fit
#displays the decision tree model graphically.
library(rattle)
fancyRpartPlot(fit, main = "Fit Using rpart Algorithm on Training Dataset")
```

##Cross-Validating the CART Model
The CART model decision tree is then fit to the validation dataset to see the accuracy of the model. A confusion matrix is set up to show the accuracy of the predicted vs. the actual excersize class.
```{r}
#Create a column of predicted values in the validation data set.
val$Pred <- predict(fit, newdata = val, type = "class")
#Produce a comparison using confusion matrix function.
confusionMatrix(val$Pred, val$classe)
```
The model accuracy is 89% using the rpart algorithm. This is acceptable, since the accuracy is above the 50% and below 95%. Any accuracy above 95% would indicate a likely 'overfitting' situation.

##Predicting the Test Outcomes Using the Model.
The prediction of the test dataset outcomes was fit to the model and shown in the final table.
```{r}
#Create a column of predicted values in the testing data set.
test$Pred <- predict(fit, newdata = test, type = "class")
#Produce a table showing the outcomes of the 20 test cases.
subset(test, select = c(user_name, Pred))
```
